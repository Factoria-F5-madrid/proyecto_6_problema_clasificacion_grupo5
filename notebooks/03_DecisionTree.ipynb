{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb96cb9e",
   "metadata": {},
   "source": [
    "# üå≥ **Modelo de Clasificaci√≥n: Decision Tree**\n",
    "\n",
    "En este notebook se entrena y eval√∫a un modelo de **√Årbol de Decisi√≥n (DecisionTreeClassifier)**  \n",
    "para predecir el nivel de satisfacci√≥n de los pasajeros de una aerol√≠nea.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç **Objetivos del notebook:**\n",
    "1. Entrenar un modelo base de √Årbol de Decisi√≥n.  \n",
    "2. Validar su rendimiento mediante **validaci√≥n cruzada (CV=5)**.  \n",
    "3. Realizar una b√∫squeda de hiperpar√°metros con **GridSearchCV**.  \n",
    "4. Evaluar el modelo optimizado y visualizar resultados.  \n",
    "5. Guardar las m√©tricas y el modelo entrenado para su comparaci√≥n posterior.\n",
    "\n",
    "---\n",
    "\n",
    "üì¶ **Nota t√©cnica:**\n",
    "- Dataset utilizado: versiones **no escaladas** (`X_train_unscaled.csv`, `X_test_unscaled.csv`).  \n",
    "- Se usa `class_weight=\"balanced\"` para compensar el leve desbalanceo de clases.  \n",
    "- M√©trica principal de evaluaci√≥n: **F1-score** sobre la clase *‚Äúsatisfied‚Äù*.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fc8456",
   "metadata": {},
   "source": [
    "## **Paso 1: Carga de librer√≠as y datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded1303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 1. Carga de librer√≠as y datasets\n",
    "# ===================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib, json, os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    ConfusionMatrixDisplay, RocCurveDisplay, classification_report\n",
    ")\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Cargar datasets no escalados ---\n",
    "X_train = pd.read_csv(\"../data/processed/X_train_unscaled.csv\")\n",
    "X_test = pd.read_csv(\"../data/processed/X_test_unscaled.csv\")\n",
    "y_train = pd.read_csv(\"../data/processed/y_train.csv\").squeeze()\n",
    "y_test = pd.read_csv(\"../data/processed/y_test.csv\").squeeze()\n",
    "\n",
    "display(Markdown(\"‚úÖ **Datasets cargados correctamente (no escalados).**\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526c0515",
   "metadata": {},
   "source": [
    "## **Paso 2: Entrenamiento del modelo base**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0230632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 2. Modelo base - √Årbol de Decisi√≥n\n",
    "# ===================================\n",
    "\n",
    "dt_base = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "dt_base.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = dt_base.predict(X_test)\n",
    "y_prob = dt_base.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# C√°lculo de m√©tricas\n",
    "metrics_base = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred, pos_label=1),\n",
    "    \"Recall\": recall_score(y_test, y_pred, pos_label=1),\n",
    "    \"F1-score\": f1_score(y_test, y_pred, pos_label=1),\n",
    "    \"ROC-AUC\": roc_auc_score(y_test, y_prob)\n",
    "}\n",
    "\n",
    "display(Markdown(\"### üìä M√©tricas del modelo base (sin optimizar)\"))\n",
    "for k, v in metrics_base.items():\n",
    "    print(f\"{k}: {v:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dcf8bd",
   "metadata": {},
   "source": [
    "## **Paso 3: Validaci√≥n cruzada (CV=5)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da8191c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 3. Validaci√≥n cruzada (Cross-Validation)\n",
    "# ===================================\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "f1_scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    dt_base, X_train, y_train,\n",
    "    cv=5,\n",
    "    scoring=f1_scorer\n",
    ")\n",
    "\n",
    "# --- Resultados individuales ---\n",
    "display(Markdown(\"üìä **Resultados individuales de la validaci√≥n cruzada (F1 por fold):**\"))\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"Fold {i}: {score:.3f}\")\n",
    "\n",
    "print(f\"\\nPromedio F1: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(x=cv_scores, color=\"lightblue\")\n",
    "sns.stripplot(x=cv_scores, color=\"darkblue\", jitter=0.05, size=6)\n",
    "plt.title(\"Distribuci√≥n del F1-score en la Validaci√≥n Cruzada (5-fold)\", fontsize=12)\n",
    "plt.xlabel(\"F1-score por fold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "üìä **Resultados individuales (F1 por fold):** { [round(x,3) for x in cv_scores] }  \n",
    "**Promedio F1 (CV):** {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3922f979",
   "metadata": {},
   "source": [
    "## **Paso 4: Tuning de hiperpar√°metros con GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6991ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 4. Tuning de hiperpar√°metros con GridSearchCV\n",
    "# ===================================\n",
    "\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "f1_scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "# -----------------------------------\n",
    "# OPCI√ìN 1: GRIDSEARCH REDUCIDA (recomendada.) \n",
    "# Ejecuci√≥n r√°pida y pr√°ctica para probar el modelo en menos tiempo \n",
    "# y obtener resultados preliminares) antes de hacer la GridSearch completa.\n",
    "# Descomentar seg√∫n el uso  y comentar la otra opci√≥n.\n",
    "# -----------------------------------\n",
    "\"\"\"\n",
    "üîπ Combinaciones posibles:\n",
    "3 √ó 2 √ó 2 √ó 1 = 12 modelos\n",
    "‚Üí Con 5-fold CV ‚Üí 12 √ó 5 = 60 entrenamientos totales\n",
    "‚è±Ô∏è Tiempo estimado: < 1 minuto en un port√°til normal.\n",
    "\n",
    "\"\"\"\n",
    "param_grid = {\n",
    "    \"max_depth\": [5, 10, None],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"criterion\": [\"gini\"]\n",
    "}\n",
    "\n",
    "# -----------------------------------\n",
    "# OPCI√ìN 2: GRIDSEARCH COMPLETA (comentar si no se usa)\n",
    "# Ejecuci√≥n m√°s precisa, m√°s completa, pero m√°s lenta.\n",
    "# Descomentar seg√∫n el uso  y comentar la otra opci√≥n.\n",
    "# -----------------------------------\n",
    "\n",
    "\"\"\"\n",
    "üîπ Combinaciones posibles:\n",
    "5 √ó 3 √ó 3 √ó 2 = 90 modelos\n",
    "‚Üí Con 5-fold CV ‚Üí 90 √ó 5 = 450 entrenamientos totales\n",
    "‚è±Ô∏è Tiempo estimado: 4‚Äì6 minutos, dependiendo del equipo.\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "param_grid = {\n",
    "    \"max_depth\": [5, 10, 15, 20, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Configuraci√≥n del GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(random_state=42, class_weight=\"balanced\"),\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Resultados\n",
    "display(Markdown(f\"\"\"\n",
    "‚úÖ **Tuning completado correctamente.**\n",
    "\n",
    "- **Mejores par√°metros:** `{grid_search.best_params_}`  \n",
    "- **Mejor F1-score medio (CV):** `{grid_search.best_score_:.3f}`\n",
    "\n",
    "üí° **Nota:**  \n",
    "Usando la malla reducida ‚Üí se entrenan 12 combinaciones √ó 5 folds = **60 modelos**.  \n",
    "Con la versi√≥n completa ‚Üí 90 √ó 5 = **450 modelos**.\n",
    "\"\"\"))\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "**üí¨ Interpretaci√≥n visual del tuning de hiperpar√°metros:**\n",
    "\n",
    "- Cada combinaci√≥n de hiperpar√°metros ha sido evaluada mediante validaci√≥n cruzada (CV=5).  \n",
    "- El par√°metro **`max_depth`** controla la profundidad m√°xima del √°rbol:  \n",
    "  - Valores bajos ‚Üí menor sobreajuste pero menor precisi√≥n.  \n",
    "  - Valores altos o `None` ‚Üí mayor capacidad predictiva, pero riesgo de *overfitting*.  \n",
    "- **`min_samples_split`** y **`min_samples_leaf`** regulan el tama√±o m√≠nimo de los nodos,  \n",
    "  suavizando el √°rbol y mejorando la generalizaci√≥n.  \n",
    "- El **criterio** (`gini` o `entropy`) define c√≥mo se mide la pureza de las divisiones.  \n",
    "  En la mayor√≠a de los casos, las diferencias son peque√±as.  \n",
    "- En la malla reducida se obtiene una buena estimaci√≥n r√°pida,  \n",
    "  mientras que la malla completa busca la combinaci√≥n √≥ptima con m√°s detalle.\n",
    "\"\"\"))\n",
    "\n",
    "# --- Visualizaci√≥n de resultados ---\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_).sort_values(by=\"mean_test_score\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "sns.barplot(\n",
    "    data=cv_results,\n",
    "    x=\"mean_test_score\",\n",
    "    y=cv_results[\"params\"].astype(str),\n",
    "    palette=\"coolwarm\",\n",
    "    hue=\"mean_test_score\",\n",
    "    dodge=False,\n",
    "    legend=False\n",
    ")\n",
    "plt.title(\"F1-score medio por combinaci√≥n de hiperpar√°metros (GridSearchCV)\", fontsize=13)\n",
    "plt.xlabel(\"Mean F1-score (CV)\")\n",
    "plt.ylabel(\"Par√°metros\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "**üí¨ Interpretaci√≥n visual:**\n",
    "- Cada barra representa una combinaci√≥n de hiperpar√°metros evaluada.  \n",
    "- Las m√°s largas indican mejor rendimiento.  \n",
    "- Si varias barras son similares ‚Üí el modelo es estable.  \n",
    "- Si hay una combinaci√≥n muy superior ‚Üí merece an√°lisis adicional.\n",
    "\"\"\"))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c91a74d",
   "metadata": {},
   "source": [
    "## **Paso 5: Evaluaci√≥n del modelo optimizado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c78aea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 5. Evaluaci√≥n del modelo optimizado\n",
    "# ===================================\n",
    "\n",
    "best_dt = grid_search.best_estimator_\n",
    "\n",
    "# --- Predicciones ---\n",
    "y_pred_opt = best_dt.predict(X_test)\n",
    "y_prob_opt = best_dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# --- C√°lculo de m√©tricas ---\n",
    "metrics_opt = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_opt),\n",
    "    \"Precision\": precision_score(y_test, y_pred_opt, pos_label=1),\n",
    "    \"Recall\": recall_score(y_test, y_pred_opt, pos_label=1),\n",
    "    \"F1-score\": f1_score(y_test, y_pred_opt, pos_label=1),\n",
    "    \"ROC-AUC\": roc_auc_score(y_test, y_prob_opt)\n",
    "}\n",
    "\n",
    "display(Markdown(\"### üìä M√©tricas del modelo optimizado (Test Set)\"))\n",
    "for k, v in metrics_opt.items():\n",
    "    print(f\"{k}: {v:.3f}\")\n",
    "\n",
    "# --- Matriz de confusi√≥n y curva ROC ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    best_dt, X_test, y_test,\n",
    "    cmap=\"Blues\",\n",
    "    display_labels=[\"0 - Neutral/Dissatisfied\", \"1 - Satisfied\"],\n",
    "    ax=axes[0]\n",
    ")\n",
    "\n",
    "\n",
    "# Curva ROC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob_opt)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "axes[1].plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"AUC = {roc_auc:.3f}\")\n",
    "axes[1].fill_between(fpr, tpr, color=\"orange\", alpha=0.25)\n",
    "axes[1].plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\")\n",
    "axes[1].set_xlim([-0.02, 1.02])\n",
    "axes[1].set_ylim([-0.02, 1.02])\n",
    "axes[1].set_xlabel(\"False Positive Rate (FPR)\")\n",
    "axes[1].set_ylabel(\"True Positive Rate (TPR)\")\n",
    "axes[1].set_title(\"Curva ROC - Decision Tree\", fontsize=12)\n",
    "axes[1].legend(loc=\"lower right\", frameon=True)\n",
    "axes[1].grid(alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "**üí¨ Interpretaci√≥n visual:**\n",
    "\n",
    "- **Matriz de Confusi√≥n:**  \n",
    "  Muestra los aciertos en la diagonal principal y los errores fuera de ella.  \n",
    "  Una alta concentraci√≥n en la diagonal indica un modelo que clasifica correctamente la mayor√≠a de los casos.  \n",
    "\n",
    "- **Curva ROC:**  \n",
    "  Representa la capacidad del modelo para distinguir entre clases.  \n",
    "  Cuanto m√°s se acerque la l√≠nea naranja al v√©rtice superior izquierdo, **mejor rendimiento**.  \n",
    "  El **AUC** resume esa capacidad (1.0 = perfecto, 0.5 = aleatorio).  \n",
    "\n",
    "- El √°rea naranja bajo la curva refleja visualmente la **tasa acumulada de aciertos** del modelo.  \n",
    "\"\"\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f32cd04",
   "metadata": {},
   "source": [
    "## **Paso 6: Guardado de resultados y modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db57b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# 6. Guardado de resultados\n",
    "# ===================================\n",
    "\n",
    "os.makedirs(\"../reports/metrics\", exist_ok=True)\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "results = {\n",
    "    \"model\": \"Decision Tree\",\n",
    "    \"best_params\": grid_search.best_params_,\n",
    "    \"metrics\": metrics_opt\n",
    "}\n",
    "\n",
    "json_path = \"../reports/metrics/decision_tree_results.json\"\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "pkl_path = \"../models/decision_tree_model.pkl\"\n",
    "joblib.dump(best_dt, pkl_path)\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "‚úÖ **Resultados y modelo guardados correctamente.**\n",
    "- üìÑ JSON: `{json_path}`\n",
    "- ü§ñ Modelo: `{pkl_path}`\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11521630",
   "metadata": {},
   "source": [
    "## Paso 7: Conclusiones finales**\n",
    "\n",
    "# üèÅ **Conclusiones del modelo Decision Tree**\n",
    "\n",
    "- El modelo de √Årbol de Decisi√≥n se entren√≥ con el dataset **no escalado**  \n",
    "  y balanceo autom√°tico de clases (`class_weight=\"balanced\"`).  \n",
    "- Se realiz√≥ **tuning de hiperpar√°metros con GridSearchCV**, mejorando la capacidad predictiva.  \n",
    "- Aunque el √°rbol simple es f√°cil de interpretar, tiende a sobreajustar con profundidad alta.  \n",
    "- Sirve como **baseline** de comparaci√≥n frente a modelos m√°s complejos  \n",
    "  como **Random Forest**, **XGBoost** o **LightGBM**.\n",
    "\n",
    "üìà Los resultados se han almacenado en:\n",
    "- `../reports/metrics/decision_tree_results.json`  \n",
    "- `../models/decision_tree_model.pkl`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
